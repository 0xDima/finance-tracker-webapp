{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67eeb83",
   "metadata": {},
   "source": [
    "# Transaction Data Normalization & Migration Notebook\n",
    "\n",
    "This notebook documents the process of cleaning, normalizing, and validating\n",
    "personal financial transaction data collected from multiple monthly Excel files\n",
    "throughout the year.\n",
    "\n",
    "The original data sources contained inconsistent formats, including:\n",
    "- mixed date representations (Excel serial dates, EU/US date strings),\n",
    "- missing or extra columns across months,\n",
    "- partially empty rows,\n",
    "- inconsistent numeric formats for transaction amounts.\n",
    "\n",
    "The goal of this notebook was to:\n",
    "- explore and understand the structure of the raw Excel data,\n",
    "- iteratively normalize dates, headers, and numeric values,\n",
    "- validate schema consistency across all months,\n",
    "- ensure that no transactions were lost during transformation,\n",
    "- prepare the data for safe insertion into a SQLite database.\n",
    "\n",
    "This notebook served as an experimental and diagnostic environment:\n",
    "all outputs have been cleared to keep it readable and suitable for version control.\n",
    "The final, production-ready logic derived from this notebook is implemented\n",
    "in a standalone Python migration script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dates_mmddyyyy(\n",
    "    series: pd.Series,\n",
    "    expected_month: int,\n",
    "    expected_year: int | None = None,\n",
    ") -> pd.Series:\n",
    "    def parse_one(v):\n",
    "        if pd.isna(v):\n",
    "            return pd.NaT\n",
    "\n",
    "        # Already a datetime-like?\n",
    "        if isinstance(v, (pd.Timestamp, )):\n",
    "            ts_candidates = [v]\n",
    "        else:\n",
    "            s = str(v).strip()\n",
    "            # Try both interpretations\n",
    "            ts_dayfirst  = pd.to_datetime(s, dayfirst=True,  errors=\"coerce\")\n",
    "            ts_monthfirst = pd.to_datetime(s, dayfirst=False, errors=\"coerce\")\n",
    "            ts_candidates = [ts_dayfirst, ts_monthfirst]\n",
    "\n",
    "        ts_candidates = [t for t in ts_candidates if not pd.isna(t)]\n",
    "        if not ts_candidates:\n",
    "            return pd.NaT\n",
    "\n",
    "        # Optional year filter (helps if your data is only 2025)\n",
    "        if expected_year is not None:\n",
    "            year_ok = [t for t in ts_candidates if t.year == expected_year]\n",
    "            if year_ok:\n",
    "                ts_candidates = year_ok\n",
    "\n",
    "        # Prefer the one that lands in the expected month (January = 1)\n",
    "        for t in ts_candidates:\n",
    "            if t.month == expected_month:\n",
    "                return t\n",
    "\n",
    "        # Fallback: return the first valid parse\n",
    "        return ts_candidates[0]\n",
    "\n",
    "    parsed = series.apply(parse_one)\n",
    "    return parsed.dt.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960332bf",
   "metadata": {},
   "source": [
    "JANUARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Folder with monthly Excel files\n",
    "DATA_DIR = Path(\"processed_data\")\n",
    "\n",
    "def load_excel_files(folder: Path) -> dict[str, pd.DataFrame]:\n",
    "    dfs = {}\n",
    "\n",
    "    for file in sorted(folder.glob(\"*.xlsx\")):\n",
    "        key = file.stem.lower()  \n",
    "        df = pd.read_excel(file)\n",
    "\n",
    "        dfs[key] = df\n",
    "\n",
    "        print(f\"Loaded {file.name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc65f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_date(value) -> str | None:\n",
    "    \"\"\"\n",
    "    Normalize date into DD-MM-YYYY.\n",
    "\n",
    "    Accepts:\n",
    "    - string dates (DD/MM/YYYY, D/M/YY, etc.)\n",
    "    - datetime / date objects\n",
    "    - NaN / NaT\n",
    "\n",
    "    Returns:\n",
    "    - formatted string or None\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "\n",
    "    # Already a datetime/date object\n",
    "    if isinstance(value, (datetime, date)):\n",
    "        return value.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    # String input\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "\n",
    "        formats = (\"%d/%m/%Y\", \"%d/%m/%y\")\n",
    "\n",
    "        for fmt in formats:\n",
    "            try:\n",
    "                return datetime.strptime(value, fmt).strftime(\"%d-%m-%Y\")\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    raise ValueError(f\"Unsupported date value: {value} ({type(value)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5189df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = load_excel_files(Path(\"/Users/test/Documents/Documents/Personal/projects/finance-tracker-webapp/data-migration/processed_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e32125",
   "metadata": {},
   "outputs": [],
   "source": [
    "january_df = dataframes[\"january\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "january_df[\"DATE\"] = january_df[\"DATE\"].apply(normalize_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70821ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "january_df = january_df.rename(columns={\n",
    "    \"DATE\": \"date\",\n",
    "    \"PAYMENT METHOD\": \"account\",\n",
    "    \"DESCRIPTION\": \"description\",\n",
    "    \"SUM\": \"sum\",\n",
    "    \"CATEGORY\": \"category\",\n",
    "    \"NOTES\": \"notes\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b91deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "january_df[\"date\"] = normalize_dates_mmddyyyy(\n",
    "    january_df[\"date\"],\n",
    "    expected_month=1,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841260bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "january_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b50cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "january_df.to_csv(\"./normalized/january.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591c9d9",
   "metadata": {},
   "source": [
    "February"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c209d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "february_df = dataframes[\"february\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e25858",
   "metadata": {},
   "outputs": [],
   "source": [
    "february_df[\"DATE\"] = (\n",
    "    pd.to_datetime(february_df[\"DATE\"], format=\"%d/%m/%y\")\n",
    "    .dt.strftime(\"%d-%m-%Y\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "february_df = february_df.rename(columns={\n",
    "    \"DATE\": \"date\",\n",
    "    \"PAYMENT METHOD\": \"account\",\n",
    "    \"DESCRIPTION\": \"description\",\n",
    "    \"SUM\": \"sum\",\n",
    "    \"CATEGORY\": \"category\",\n",
    "    \"NOTES\": \"notes\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "february_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebdabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "february_df['date'] = normalize_dates_mmddyyyy(\n",
    "    february_df[\"date\"],\n",
    "    expected_month=2,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ed0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "february_df.to_csv(\"./normalized/february.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b66bbb",
   "metadata": {},
   "source": [
    "MARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_df = dataframes[\"march\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_df[\"DATE\"] = pd.to_datetime(march_df[\"DATE\"], format=\"%d/%m/%y\").dt.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a85b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_df = march_df.rename(columns={\n",
    "    \"DATE\": \"date\",\n",
    "    \"PAYMENT METHOD\": \"account\",\n",
    "    \"DESCRIPTION\": \"description\",\n",
    "    \"SUM\": \"sum\",\n",
    "    \"CATEGORY\": \"category\",\n",
    "    \"NOTES\": \"notes\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "march_df.to_csv(\"./normalized/march.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc83d84",
   "metadata": {},
   "source": [
    "April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "april_df = dataframes[\"april\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "april_df[\"DATE\"] = (\n",
    "    pd.to_datetime(april_df[\"DATE\"], format=\"%d/%m/%y\")\n",
    "    .dt.strftime(\"%d-%m-%Y\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f393160",
   "metadata": {},
   "outputs": [],
   "source": [
    "april_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d964ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mixed_date(value):\n",
    "    # Case 1: Excel serial date (int / float)\n",
    "    if isinstance(value, (int, float)):\n",
    "        return pd.to_datetime(value, unit=\"D\", origin=\"1899-12-30\").strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    # Case 2: EU string date (DD/MM/YYYY)\n",
    "    if isinstance(value, str):\n",
    "        return pd.to_datetime(value, format=\"%d/%m/%Y\").strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "april_df = april_df.rename(columns={\n",
    "    \"Date\": \"date\",\n",
    "    \"Description\": \"description\",\n",
    "    \"Sum\": \"sum\",\n",
    "    \"Category\": \"category\",\n",
    "    \"Notes\": \"notes\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "april_df[\"account\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34296978",
   "metadata": {},
   "outputs": [],
   "source": [
    "april_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c65a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "april_df.to_csv(\"./normalized/april.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533c84e",
   "metadata": {},
   "source": [
    "May"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df = dataframes['may']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bff181",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df['txn_date'] = may_df['txn_date'].apply(normalize_mixed_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df[\"account\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22ec7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c175829",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df = may_df.rename(columns={\n",
    "    \"txn_date\": \"date\",\n",
    "    \"amount\": \"sum\",\n",
    "    \"note\": \"notes\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef05d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df['date'] = normalize_dates_mmddyyyy(\n",
    "    may_df[\"date\"],\n",
    "    expected_month=5,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df['date'] = normalize_dates_mmddyyyy(\n",
    "    may_df[\"date\"],\n",
    "    expected_month=5,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032035de",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df.to_csv(\"./normalized/may.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c5694",
   "metadata": {},
   "source": [
    "June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df = dataframes[\"june\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df = june_df.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6335ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df['txn_date'] = pd.to_datetime(june_df[\"txn_date\"]).dt.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df = june_df.drop(columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df['date'] = normalize_dates_mmddyyyy(\n",
    "    june_df[\"date\"],\n",
    "    expected_month=6,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e407f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb967357",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df = june_df.rename(columns={\n",
    "    \"txn_date\": \"date\",\n",
    "    \"amount\": \"sum\",\n",
    "    \"note\":\"notes\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcac18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "june_df.to_csv(\"./normalized/june.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b8037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5524139",
   "metadata": {},
   "source": [
    "July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd19b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df = dataframes['july']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110f6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0051da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "\n",
    "def normalize_any_date(v):\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "\n",
    "    # already parsed datetime/date\n",
    "    if isinstance(v, (datetime, date)):\n",
    "        return v.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    # excel serial (int/float)\n",
    "    if isinstance(v, (int, float)):\n",
    "        return pd.to_datetime(v, unit=\"D\", origin=\"1899-12-30\").strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    # strings (like \"13/07/2025\" or even \"45664\" as string)\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip()\n",
    "\n",
    "        if s.isdigit():  # handles \"45664\" stored as text\n",
    "            n = int(s)\n",
    "            return pd.to_datetime(n, unit=\"D\", origin=\"1899-12-30\").strftime(\"%d-%m-%Y\")\n",
    "\n",
    "        return datetime.strptime(s, \"%d/%m/%Y\").strftime(\"%d-%m-%Y\")\n",
    "\n",
    "    raise ValueError(f\"Unsupported date value: {v} ({type(v)})\")\n",
    "\n",
    "july_df[\"date\"] = july_df[\"date\"].apply(normalize_any_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df['date'] = normalize_dates_mmddyyyy(\n",
    "    july_df[\"date\"],\n",
    "    expected_month=7,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "july_df.to_csv(\"./normalized/july.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0cbe53",
   "metadata": {},
   "source": [
    "August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "august_df = dataframes['august']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "august_df['date'] = august_df['date'].apply(normalize_any_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fe7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "august_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "august_df['date'] = normalize_dates_mmddyyyy(\n",
    "    august_df[\"date\"],\n",
    "    expected_month=8,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c765c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "august_df.to_csv(\"./normalized/august.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04cad1",
   "metadata": {},
   "source": [
    "September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "september_df = dataframes[\"september\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62859e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "september_df['txn_date'] = september_df['txn_date'].apply(normalize_any_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "september_df = september_df.rename(columns={\n",
    "    \"txn_date\": \"date\",\n",
    "    \"amount\": \"sum\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "september_df['date'] = normalize_dates_mmddyyyy(\n",
    "    september_df[\"date\"],\n",
    "    expected_month=9,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "september_df.to_csv(\"./normalized/september.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11e3c2",
   "metadata": {},
   "source": [
    "October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "october_df = dataframes['october']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a73acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "october_df['date'] = october_df['date'].apply(normalize_any_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee37649",
   "metadata": {},
   "outputs": [],
   "source": [
    "october_df['date'] = normalize_dates_mmddyyyy(\n",
    "    october_df[\"date\"],\n",
    "    expected_month=10,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "october_df.to_csv(\"./normalized/october.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce65ac6",
   "metadata": {},
   "source": [
    "November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "november_df = dataframes['november']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "november_df['txn_date'] = november_df['txn_date'].apply(normalize_any_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ba4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "november_df = november_df.rename(columns={\n",
    "    \"txn_date\": \"date\",\n",
    "    \"amount\": \"sum\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b75565",
   "metadata": {},
   "outputs": [],
   "source": [
    "november_df['date'] = normalize_dates_mmddyyyy(\n",
    "    november_df[\"date\"],\n",
    "    expected_month=11,\n",
    "    expected_year=2025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e079f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "november_df.to_csv(\"./normalized/november.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae4ae5",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3785959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "REQUIRED_COLS = {\"date\", \"description\", \"sum\", \"category\", \"notes\", \"account\"}\n",
    "DATE_RE = re.compile(r\"^\\d{2}-\\d{2}-\\d{4}$\")\n",
    "\n",
    "def validate_normalized_csvs(folder: str | Path) -> dict:\n",
    "    folder = Path(folder)\n",
    "    csv_files = sorted(folder.glob(\"*.csv\"))\n",
    "\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No .csv files found in: {folder}\")\n",
    "\n",
    "    report = {\n",
    "        \"files_checked\": 0,\n",
    "        \"header_ok\": True,\n",
    "        \"date_ok\": True,\n",
    "        \"sum_ok\": True,\n",
    "        \"issues\": [],   # list of dicts\n",
    "    }\n",
    "\n",
    "    baseline_cols = None\n",
    "\n",
    "    for f in csv_files:\n",
    "        df = pd.read_csv(f)\n",
    "        report[\"files_checked\"] += 1\n",
    "\n",
    "        cols = set(df.columns.str.strip().str.lower())\n",
    "        missing = REQUIRED_COLS - cols\n",
    "        extra = cols - REQUIRED_COLS\n",
    "\n",
    "        if missing:\n",
    "            report[\"header_ok\"] = False\n",
    "            report[\"issues\"].append({\n",
    "                \"file\": f.name,\n",
    "                \"type\": \"missing_columns\",\n",
    "                \"details\": sorted(missing),\n",
    "            })\n",
    "\n",
    "        # optional: flag extra columns (not fatal)\n",
    "        if extra:\n",
    "            report[\"issues\"].append({\n",
    "                \"file\": f.name,\n",
    "                \"type\": \"extra_columns\",\n",
    "                \"details\": sorted(extra),\n",
    "            })\n",
    "\n",
    "        # check all files have same headers (ignoring order)\n",
    "        if baseline_cols is None:\n",
    "            baseline_cols = cols\n",
    "        elif cols != baseline_cols:\n",
    "            report[\"header_ok\"] = False\n",
    "            report[\"issues\"].append({\n",
    "                \"file\": f.name,\n",
    "                \"type\": \"header_mismatch_vs_first_file\",\n",
    "                \"details\": {\n",
    "                    \"missing_vs_first\": sorted(baseline_cols - cols),\n",
    "                    \"extra_vs_first\": sorted(cols - baseline_cols),\n",
    "                },\n",
    "            })\n",
    "\n",
    "        # normalize column names access\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "        # --- DATE checks ---\n",
    "        if \"date\" in df.columns:\n",
    "            # ensure string and basic format DD-MM-YYYY\n",
    "            date_str = df[\"date\"].astype(str).str.strip()\n",
    "            bad_format = df[~date_str.fillna(\"\").str.match(DATE_RE)]\n",
    "            # allow empty date only if whole row is empty-ish; but for DB it's usually not ok:\n",
    "            bad_format = bad_format[date_str.notna() & (date_str != \"nan\")]\n",
    "\n",
    "            if len(bad_format) > 0:\n",
    "                report[\"date_ok\"] = False\n",
    "                report[\"issues\"].append({\n",
    "                    \"file\": f.name,\n",
    "                    \"type\": \"bad_date_format\",\n",
    "                    \"details\": f\"{len(bad_format)} rows not matching DD-MM-YYYY (example: {bad_format['date'].iloc[0]!r})\",\n",
    "                })\n",
    "\n",
    "            # parseability check (strict)\n",
    "            parsed = pd.to_datetime(date_str, format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "            bad_parse = df[parsed.isna() & ~(date_str.isna() | (date_str == \"nan\"))]\n",
    "            if len(bad_parse) > 0:\n",
    "                report[\"date_ok\"] = False\n",
    "                report[\"issues\"].append({\n",
    "                    \"file\": f.name,\n",
    "                    \"type\": \"unparseable_dates\",\n",
    "                    \"details\": f\"{len(bad_parse)} rows unparseable (example: {bad_parse['date'].iloc[0]!r})\",\n",
    "                })\n",
    "\n",
    "        # --- SUM checks ---\n",
    "        if \"sum\" in df.columns:\n",
    "            # handle \"1,23\" -> \"1.23\" and strip spaces\n",
    "            sum_clean = (\n",
    "                df[\"sum\"]\n",
    "                .astype(str)\n",
    "                .str.replace(\" \", \"\", regex=False)\n",
    "                .str.replace(\",\", \".\", regex=False)\n",
    "                .str.strip()\n",
    "            )\n",
    "            sum_num = pd.to_numeric(sum_clean, errors=\"coerce\")\n",
    "            bad_sum = df[sum_num.isna() & ~(sum_clean.isna() | (sum_clean == \"nan\") | (sum_clean == \"\"))]\n",
    "\n",
    "            if len(bad_sum) > 0:\n",
    "                report[\"sum_ok\"] = False\n",
    "                report[\"issues\"].append({\n",
    "                    \"file\": f.name,\n",
    "                    \"type\": \"non_numeric_sum\",\n",
    "                    \"details\": f\"{len(bad_sum)} rows have non-numeric sum (example: {bad_sum['sum'].iloc[0]!r})\",\n",
    "                })\n",
    "\n",
    "        # --- critical empties (warnings, not fatal) ---\n",
    "        critical = []\n",
    "        for c in [\"date\", \"description\", \"sum\"]:\n",
    "            if c in df.columns:\n",
    "                n_missing = df[c].isna().sum()\n",
    "                if n_missing:\n",
    "                    critical.append(f\"{c}: {n_missing}\")\n",
    "        if critical:\n",
    "            report[\"issues\"].append({\n",
    "                \"file\": f.name,\n",
    "                \"type\": \"missing_critical_fields_warning\",\n",
    "                \"details\": \", \".join(critical),\n",
    "            })\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = validate_normalized_csvs(\"./normalized\")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53918fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "normalized_dir = Path(\"./normalized\")\n",
    "\n",
    "dfs = []\n",
    "for csv_file in sorted(normalized_dir.glob(\"*.csv\")):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"source_file\"] = csv_file.name  # optional but very useful\n",
    "    dfs.append(df)\n",
    "\n",
    "all_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f56f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[(df[\"date\"] >= \"2025-03-01\") & (df[\"date\"] < \"2025-04-01\"), \"amount_eur\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecd209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"date\"] >= \"2025-03-01\") & (df[\"date\"] < \"2025-04-01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66aa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
